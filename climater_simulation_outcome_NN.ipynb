{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiSg/uzfNg87Dp/ykLcBeo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IfeoluwaRuth/Deep-Learning/blob/main/climater_simulation_outcome_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AZFqMsnfPNLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to explore the two libraries with different activation function and optimizer on the Climate model simulation crashes dataset (https://archive.ics.uci.edu/dataset/252/climate+model+simulation+crashes) in order to predict climate model simulation outcomes (fail or succeed) given scaled values of climate model input parameters.\n",
        "\n",
        "This dataset contains records of simulation crashes encountered during climate model uncertainty quantification (UQ) ensembles.\n",
        "Column 1: Latin hypercube study ID (study 1 to study 3)\n",
        "Column 2: simulation ID (run 1 to run 180)\n",
        "Columns 3-20: values of 18 climate model parameters scaled in the interval [0, 1]\n",
        "Column 21: simulation outcome (0 = failure, 1 = success)\n",
        "\n",
        "The MLPClassifier is a library from the sklearn.neural_network module in the Scikit-learn framework, which provides tools for machine learning, including simple neural networks. On the other hand, TensorFlow is a deep learning framework designed for creating more complex and scalable neural network models."
      ],
      "metadata": {
        "id": "byNyxIqQRE9V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-thBk3No4dyG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## import dataset\n",
        "data = pd.read_csv(\"pop_failures.csv\")\n",
        "\n",
        "# Print column names\n",
        "print(\"data column name:\")\n",
        "print(data.columns)\n",
        "\n",
        "# Print dimensions of the dataset\n",
        "print(\"The dimension of the dataset is:\")\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "j4XNsAuD4lAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "lM-4jjEIoBT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "FZrWPiawoHxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dEVx33SroHep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'outcome' and count the occurrences of each label to ascertain the state of balancing in the dataset\n",
        "data_label_count = data.groupby('outcome').size().reset_index(name='count')\n",
        "print(data_label_count)\n",
        "\n",
        "data_label_count = data['outcome'].value_counts()\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))\n",
        "data_label_count.plot(kind='bar', color='skyblue')\n",
        "plt.title(\"Distribution of climate model success outcome\")\n",
        "plt.xlabel(\"Outcome\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.savefig(\"data_label_hist.png\")  #save the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vLkIVih3nrA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-KFNwDHMnqu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate target and features\n",
        "X = data.drop(columns=['outcome','Study', 'Run'])\n",
        "y = data['outcome']\n",
        "\n",
        "\n",
        "# Label Encode the target variable (Toilet_type)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=123)"
      ],
      "metadata": {
        "id": "n18tyaI3oL7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "  'model_sgd' : MLPClassifier(max_iter=500,hidden_layer_sizes=(300,), activation='relu', solver = 'sgd'),\n",
        "  'model_adam': MLPClassifier(max_iter=500,hidden_layer_sizes=(300,), activation='relu', solver = 'adam'),\n",
        "  'model_lbfgs' : MLPClassifier(max_iter=500,hidden_layer_sizes=(300,), activation='relu', solver = 'lbfgs')\n",
        "}\n",
        "# Train and evaluate each model\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    results[name] = report\n",
        "\n",
        "# Display the evaluation results for each model\n",
        "for model_name, result in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Accuracy: {result['accuracy']:.2f}\")\n",
        "    print(f\"Weighted F1-score: {result['weighted avg']['f1-score']:.2f}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "jb_uJ7JQpAAC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}